# Задание 2: Токенизация и лемматизация

## Описание
Программа для выделения отдельных слов (токенизации) из сохраненных HTML-документов и группировки их по леммам.

## Функциональность
1. Чтение HTML-файлов из директории
2. Извлечение текста из HTML (удаление тегов и JavaScript)
3. Токенизация текста (разбиение на слова)
4. Фильтрация стоп-слов, чисел и "мусора"
5. Лемматизация токенов (приведение к начальной форме)
6. Сохранение результатов в файлы

## Требования
Для работы программы необходимо установить следующие библиотеки:
```
pip install -r requirements.txt
```

## Использование
```bash
python tokenizer.py
```

## Результаты
Программа создает два файла:
- `tokens.txt` - список токенов (по одному на строку)
- `lemmas.txt` - список лемматизированных токенов (формат: `<лемма>: <токен1> <токен2> ... <токенN>`)

## Особенности реализации
- Для извлечения текста из HTML используется Beautiful Soup
- Для лемматизации используется pymystem3 (хорошо работает с русским языком)
- Фильтрация токенов включает:
  - Удаление стоп-слов (предлогов, союзов)
  - Удаление чисел и токенов, содержащих не только буквы
  - Игнорирование слов короче 3 символов
- Результаты сохраняются в формате, указанном в задании 