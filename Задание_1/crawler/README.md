# Простой веб-краулер

Программа для скачивания и сохранения веб-страниц на русском языке из предварительно подготовленного списка URL.

## Функциональность

- Загрузка URL из конфигурационного файла
- Скачивание минимум 100 текстовых страниц
- Сохранение страниц в HTML-формате (с сохранением разметки)
- Создание индексного файла, связывающего номера файлов с исходными URL
- Задержка между запросами для предотвращения перегрузки серверов

## Структура проекта

- `ultra_simple_crawler.py` - основной скрипт краулера
- `config/urls.txt` - список URL для скачивания
- `data/pages/` - директория с сохраненными HTML-страницами
- `data/index.txt` - индексный файл
- `requirements.txt` - зависимости проекта

## Установка и запуск

1. Клонировать репозиторий
2. Установить зависимости: `pip install -r requirements.txt`
3. Запустить краулер: `python ultra_simple_crawler.py`

## Результаты

- Более 100 сохраненных HTML-страниц на русском языке
- Индексный файл с соответствием номеров файлов и оригинальных URL
